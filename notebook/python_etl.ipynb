{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05afdae6-6ced-491b-be2e-e6d9204e0998",
   "metadata": {},
   "source": [
    "# Clash Royale API to SQL Server ETL (Testing Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e76be6-c193-4a09-8653-75bb9b92e34b",
   "metadata": {},
   "source": [
    "## I. Set up API and sql server connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51ea905-532b-465b-b099-314bf3347b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..')) # Add project root (1 level up from notebook/)\n",
    "from configs import config\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from pytz import UTC\n",
    "from sqlalchemy import create_engine, text\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3ea94-a1fe-446e-ab50-dfe7940bcdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step up API access\n",
    "api_key = config.API_KEY['Key']\n",
    "headers = {'Authorization': f'Bearer {api_key}'}\n",
    "base_url = 'https://api.clashroyale.com/v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b176e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../configs/config.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "username = config['username']\n",
    "password = config['password']\n",
    "server = config['server']\n",
    "database = config['database']\n",
    "\n",
    "connection_string = (\n",
    "    f\"mssql+pyodbc://{username}:{password}@{server}/{database}\"\n",
    "    \"?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "    \"&charset=utf8\"\n",
    "    \"&autocommit=True\"\n",
    ")\n",
    "\n",
    "engine = create_engine(connection_string, connect_args={\"unicode_results\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35513eeb-c975-4a8a-96bb-ee176f39c2ff",
   "metadata": {},
   "source": [
    "## II. Create helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c70457",
   "metadata": {},
   "source": [
    "### i. Season schedule functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d53bda54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to generate season id and date range for last n completed sns\n",
    "def last_n_completed_seasons(n=3, ref_date=None):\n",
    "    ref_date = ref_date or datetime.utcnow()\n",
    "\n",
    "    # find the first monday of each month (day of season reset) going back\n",
    "    months_back = n + 2\n",
    "    first_mondays = []\n",
    "    for i in range(months_back):\n",
    "        m = (ref_date.month - i - 1) % 12 + 1  \n",
    "        y = ref_date.year if (ref_date.month - i - 1) >= 0 else ref_date.year - 1 # handles cases of backtracking into previous year\n",
    "\n",
    "        # checks first week of the month to find the first monday\n",
    "        for d in range(1, 8):\n",
    "            date = datetime(year=y, month=m, day=d)\n",
    "            if datetime.weekday(date) == 0: # Monday is denoted as 0\n",
    "                first_mondays.append(date)\n",
    "                break\n",
    "    first_mondays = sorted(first_mondays)\n",
    "\n",
    "    # build seasons (start date, end date)\n",
    "    seasons = []\n",
    "    for i in range(len(first_mondays) - 1):\n",
    "        start = first_mondays[i] + timedelta(hours=9) # specific start time for seasons\n",
    "        end = first_mondays[i+1] + timedelta(hours=9) - timedelta(seconds=1)\n",
    "\n",
    "        if end < ref_date:\n",
    "            season_id = start.strftime('%Y-%m') # extract season_id from season start datetime\n",
    "            seasons.append({'season_id': season_id,\n",
    "                            'sn_start_date': start.replace(tzinfo=UTC),\n",
    "                            'sn_end_date': end.replace(tzinfo=UTC)\n",
    "            })\n",
    "    return pd.DataFrame(seasons)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb48fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to generate current and future season_id and date range\n",
    "def current_plus_n_seasons(n=3, ref_date=None):\n",
    "    ref_date = ref_date or datetime.utcnow()\n",
    "    months_forward = n + 4\n",
    "    \n",
    "    first_mondays = []\n",
    "    for i in range(-2, months_forward):\n",
    "        m = (ref_date.month + i - 1) % 12 + 1\n",
    "        y = ref_date.year + ((ref_date.month + i - 1) // 12)\n",
    "\n",
    "        for d in range(1, 8):\n",
    "            date = datetime(year=y, month=m, day=d)\n",
    "            if datetime.weekday(date) == 0:\n",
    "                first_mondays.append(date)\n",
    "                break\n",
    "    first_mondays = sorted(set(first_mondays))\n",
    "\n",
    "    # build seasons as list of dicts with each dict representing a season row\n",
    "    seasons = []\n",
    "    \n",
    "    for i in range(len(first_mondays) - 1):\n",
    "        start = first_mondays[i] + timedelta(hours=9)\n",
    "        end = first_mondays[i+1] + timedelta(hours=9) - timedelta(seconds=1)\n",
    "        if start <= ref_date <= end: # add current season\n",
    "            season_id = start.strftime('%Y-%m')\n",
    "            seasons.append({'season_id': season_id,\n",
    "                            'sn_start_date': start.replace(tzinfo=UTC),\n",
    "                            'sn_end_date': end.replace(tzinfo=UTC)\n",
    "            })\n",
    "        elif start > ref_date and len(seasons) < n + 1:  # add up to n future\n",
    "            seasons.append({'season_id': start.strftime('%Y-%m'),\n",
    "                            'sn_start_date': start.replace(tzinfo=UTC),\n",
    "                            'sn_end_date': end.replace(tzinfo=UTC)\n",
    "            })   \n",
    "    # return as df\n",
    "    return pd.DataFrame(seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45d591be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to find season_id based on battle_time\n",
    "def battle_time_to_sid(battle_time, past_n=3, future_n=3):\n",
    "    battle_time = pd.to_datetime(battle_time, utc =True)\n",
    "    past_df = last_n_completed_seasons(n=past_n)\n",
    "    future_df = current_plus_n_seasons(n=future_n)\n",
    "    all_seasons_df = pd.concat([past_df, future_df], ignore_index=True).drop_duplicates(subset='season_id')\n",
    "    \n",
    "    for _, season in all_seasons_df.iterrows():\n",
    "        if season['sn_start_date'] <= battle_time <= season['sn_end_date']:\n",
    "            return season['season_id']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8d830d",
   "metadata": {},
   "source": [
    "### ii. Existing data check functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e298e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to get existing values from any column of db table\n",
    "def get_existing_data(engine, column, table): # column and table params will be strings\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(f'SELECT DISTINCT {column} FROM {table}'))\n",
    "        return [getattr(row, column) for row in result]\n",
    "\n",
    "# create function to get match_view_id:match_key mapping in matches db table\n",
    "def get_match_key_mapping (engine):\n",
    "    with engine.connect() as conn:\n",
    "        match_key_map = pd.read_sql('SELECT match_view_id, match_key FROM matches;', conn)\n",
    "        return match_key_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5614b8",
   "metadata": {},
   "source": [
    "### iii. Database insert (only) and delete functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82b278cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to insert new rows of data into target db table; use for tables where existing rows are static data\n",
    "def insert_new_rows(engine, source_df, target_table, method): # target_table and method params will be strings\n",
    "    source_df.to_sql(name=target_table,\n",
    "                     con=engine,\n",
    "                     if_exists='append',\n",
    "                     index=False, \n",
    "                     method=method\n",
    "    )\n",
    "\n",
    "# create function to delete rows from db (for deleted / banned players)\n",
    "def purge_failed_players(engine, failed_players):\n",
    "    with engine.begin() as conn:\n",
    "        for player_id in failed_players:\n",
    "            conn.execute(text(\"DELETE FROM match_cards WHERE player_id = :pid\"), {\"pid\": player_id})\n",
    "            conn.execute(text(\"DELETE FROM matches WHERE player_id = :pid\"), {\"pid\": player_id})\n",
    "            conn.execute(text(\"DELETE FROM season_rankings WHERE player_id = :pid\"), {\"pid\": player_id})\n",
    "            conn.execute(text(\"DELETE FROM players WHERE player_id = :pid\"), {\"pid\": player_id})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a9e1d4",
   "metadata": {},
   "source": [
    "### iv. Database upsert / merge functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8629c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to upsert (update existing + insert new) player data in players db table\n",
    "def upsert_player_info(engine, df):\n",
    "     player_info_tuples = df.values.tolist() # query expects column values passed as tuples\n",
    "     \n",
    "     query = '''\n",
    "                MERGE INTO players AS target\n",
    "                USING (VALUES (?,?,?,?,?,?,?,?,?,?,?)) AS \n",
    "                    source (player_id, player_name, exp_lvl, road_trophies, best_road_trophies, wins,\n",
    "                            losses, life_time_battles, max_challenge_wins, clan_id, url_encoded_pid)\n",
    "                ON target.player_id = source.player_id\n",
    "                WHEN MATCHED THEN\n",
    "                    UPDATE SET\n",
    "                        player_name = source.player_name,\n",
    "                        exp_lvl = source.exp_lvl,\n",
    "                        road_trophies = source.road_trophies,\n",
    "                        best_road_trophies = source.best_road_trophies,\n",
    "                        wins = source.wins,\n",
    "                        losses = source.losses,\n",
    "                        life_time_battles = source.life_time_battles,\n",
    "                        max_challenge_wins = source.max_challenge_wins,\n",
    "                        clan_id = source.clan_id,\n",
    "                        url_encoded_pid = source.url_encoded_pid\n",
    "                WHEN NOT MATCHED THEN\n",
    "                    INSERT (player_id, player_name, exp_lvl, road_trophies, best_road_trophies, wins, \n",
    "                            losses, life_time_battles, max_challenge_wins, clan_id, url_encoded_pid)\n",
    "                        VALUES (source.player_id, source.player_name, source.exp_lvl, source.road_trophies,\n",
    "                                source.best_road_trophies, source.wins, source.losses, source.life_time_battles,\n",
    "                                source.max_challenge_wins, source.clan_id, source.url_encoded_pid);                                                            \n",
    "     '''\n",
    "     \n",
    "     with engine.raw_connection().cursor() as cursor:\n",
    "        cursor.executemany(query, player_info_tuples)\n",
    "        cursor.connection.commit()\n",
    "\n",
    "# create function to upsert clan data in clans db table\n",
    "def upsert_clan_info(engine, df):\n",
    "    clan_info_tuples = df.values.tolist()\n",
    "\n",
    "    query = '''\n",
    "                MERGE INTO clans AS target\n",
    "                USING (VALUES (?,?,?,?,?,?,?,?,?,?)) AS\n",
    "                    source (clan_id, clan_name, clan_type, badge_id, clan_score, clan_war_trophies,\n",
    "                            clan_location, required_trophies, members, url_encoded_cid)\n",
    "                ON target.clan_id = source.clan_id\n",
    "                WHEN MATCHED THEN\n",
    "                    UPDATE SET\n",
    "                        clan_name = source.clan_name,\n",
    "                        clan_type = source.clan_type,\n",
    "                        badge_id = source.badge_id,\n",
    "                        clan_score = source.clan_score,\n",
    "                        clan_war_trophies = source.clan_war_trophies,\n",
    "                        clan_location = source.clan_location,\n",
    "                        required_trophies = source.required_trophies,\n",
    "                        members = source.members,\n",
    "                        url_encoded_cid = source.url_encoded_cid\n",
    "                WHEN NOT MATCHED THEN\n",
    "                    INSERT (clan_id, clan_name, clan_type, badge_id, clan_score, clan_war_trophies,\n",
    "                            clan_location, required_trophies, members, url_encoded_cid)\n",
    "                        VALUES (source.clan_id, source.clan_name, source.clan_type, source.badge_id, source.clan_score,\n",
    "                                source.clan_war_trophies, source.clan_location, source.required_trophies,\n",
    "                                source.members, source.url_encoded_cid);    \n",
    "     '''\n",
    "    with engine.raw_connection().cursor() as cursor:\n",
    "        cursor.executemany(query, clan_info_tuples)\n",
    "        cursor.connection.commit()\n",
    "\n",
    "# create function to upsert card data in cards db table\n",
    "def upsert_card_info(engine, df):\n",
    "    card_info_tuples = df.where(pd.notnull(df), 0).values.tolist()\n",
    "\n",
    "    query = '''\n",
    "                MERGE INTO cards AS target\n",
    "                USING (VALUES (?, ?, ?, ?, ?)) AS\n",
    "                    source (card_id, card_name, rarity, elixir_cost, evo_status)\n",
    "                ON target.card_id = source.card_id\n",
    "                WHEN MATCHED THEN\n",
    "                    UPDATE SET\n",
    "                        card_name = source.card_name,\n",
    "                        rarity = source.rarity,\n",
    "                        elixir_cost = source.elixir_cost,\n",
    "                        evo_status = source.evo_status\n",
    "                WHEN NOT MATCHED THEN\n",
    "                    INSERT (card_id, card_name, rarity, elixir_cost, evo_status)\n",
    "                        VALUES (source.card_id, source.card_name, source.rarity, source.elixir_cost, source.evo_status);\n",
    "    '''\n",
    "\n",
    "    with engine.raw_connection().cursor() as cursor:\n",
    "        cursor.executemany(query, card_info_tuples)\n",
    "        cursor.connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b13258",
   "metadata": {},
   "source": [
    "### iv. API data pull functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "661e9c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to pull player data into df\n",
    "def get_player_info (player_ids):\n",
    "    player_details = []\n",
    "    failed_ids = [] # will catch any player_ids that fail to pull\n",
    "    \n",
    "    for player_id in player_ids:\n",
    "        try:\n",
    "            response = requests.get(f'{base_url}/players/{player_id}', headers=headers)\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                print(f'Failed request for player {player_id.replace(\"%23\", \"#\")}: {response.status_code}')\n",
    "                failed_ids.append(player_id.replace('%23', '#'))\n",
    "                continue\n",
    "        \n",
    "            json_data = response.json()\n",
    "            if 'tag' not in json_data:\n",
    "                print(f'Invalid response for player {player_id.replace(\"%23\", \"#\")}: {json_data}')\n",
    "                failed_ids.append(player_id.replace('%23', '#'))\n",
    "                continue\n",
    "        \n",
    "            player_info = {'player_id': json_data['tag'],\n",
    "                           'player_name': json_data['name'],\n",
    "                           'exp_lvl': json_data['expLevel'],\n",
    "                           'road_trophies': json_data['trophies'],\n",
    "                           'best_road_trophies': json_data['bestTrophies'],\n",
    "                           'wins': json_data['wins'],\n",
    "                           'losses': json_data['losses'],\n",
    "                           'life_time_battles': json_data['battleCount'],\n",
    "                           'max_challenge_wins': json_data['challengeMaxWins'],\n",
    "                           'clan_id': (json_data.get('clan') or {}).get('tag')\n",
    "            }\n",
    "            player_details.append(player_info)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Exception for player {player_id.replace('%23', '#')}: {e}\")\n",
    "            failed_ids.append(player_id.replace('%23', '#'))\n",
    "        \n",
    "        time.sleep(0.1) # stay under API limit\n",
    "        \n",
    "    players = pd.DataFrame(player_details)\n",
    "\n",
    "    if not players.empty:\n",
    "        players['url_encoded_pid'] = players['player_id'].str.replace('#', '%23')\n",
    "        \n",
    "    return players, failed_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fdc04e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to pull season rankings from api into df\n",
    "def get_season_rankings (season_ids):\n",
    "    top_players = []\n",
    "    with open('../dropped_data/dropped_players.json', 'r') as f:\n",
    "        dropped_players = json.load(f) # load in dynamic list of known deleted or banned players to filter out\n",
    "\n",
    "    for season in season_ids:\n",
    "        response = requests.get(f'{base_url}/locations/global/pathoflegend/{season}/rankings/players?limit=100', headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f'Failed to fetch data for {season}.')\n",
    "            continue # will continue run even if it fails to fetch data for a particular sn\n",
    "\n",
    "        for player in response.json().get('items', []):\n",
    "            if player['tag'] not in dropped_players: # apply filter                                                                                                    \n",
    "                rank_info = {'player_id': player['tag'], # pull fields of interest\n",
    "                            'season_id': season,\n",
    "                            'rank': player['rank'],\n",
    "                            'rating': player['eloRating']\n",
    "                }\n",
    "                top_players.append(rank_info)\n",
    "                \n",
    "    # create a DataFrame from the top players data\n",
    "    season_rankings = pd.DataFrame(top_players)\n",
    "    \n",
    "    return season_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ef727b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to pull clan data into df\n",
    "def get_clan_info (clan_ids):\n",
    "    clan_details = []\n",
    "    failed_clans = []\n",
    "    for clan_id in clan_ids:\n",
    "        try:\n",
    "            response = requests.get(f'{base_url}/clans/{clan_id}', headers=headers)\n",
    "            if response.status_code != 200:\n",
    "                    print(f'Failed request for clan {clan_id.replace(\"%23\", \"#\")}: {response.status_code}')\n",
    "                    failed_clans.append(clan_id.replace(\"%23\", \"#\"))\n",
    "                    continue\n",
    "            \n",
    "            json_data = response.json()\n",
    "            if 'tag' not in json_data:\n",
    "                print(f'Invalid response for clan {clan_id.replace(\"23\", \"#\")}: {json_data}')\n",
    "                failed_clans.append(clan_id.replace('23', '#'))\n",
    "                continue\n",
    "\n",
    "            clan_info = {'clan_id': json_data['tag'],\n",
    "                        'clan_name': json_data['name'],\n",
    "                        'clan_type': json_data['type'],\n",
    "                        'badge_id': json_data['badgeId'],\n",
    "                        'clan_score': json_data['clanScore'],\n",
    "                        'clan_war_trophies': json_data['clanWarTrophies'],\n",
    "                        'clan_location': json_data.get('location').get('name'),\n",
    "                        'required_trophies': json_data['requiredTrophies'],\n",
    "                        'members': json_data['members']\n",
    "            }\n",
    "            clan_details.append(clan_info)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Exception for clan {clan_id.replace('%23', '#')}: {e}\")\n",
    "            failed_clans.append(clan_id.replace('%23','#'))\n",
    "\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    clans = pd.DataFrame(clan_details)\n",
    "    clans['url_encoded_cid'] = clans['clan_id'].str.replace('#', '%23')\n",
    "    clans['badge_id'] = clans['badge_id'].astype(str)  # ensure badge_id is string type\n",
    "    \n",
    "    return clans, failed_clans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc6a61e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to pull card data into df\n",
    "def get_card_info():\n",
    "    card_info = []\n",
    "    response = requests.get(f'{base_url}/cards', headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f'Failed to fetch card data: {response.status_code}')\n",
    "        return pd.DataFrame()  # return empty DataFrame if request fails\n",
    "    json_data = response.json().get('items', [])\n",
    "    for card in json_data:\n",
    "        card_details = {'card_id': card['id'],\n",
    "                        'card_name': card['name'],\n",
    "                        'rarity': card['rarity'],\n",
    "                        'elixir_cost': card.get('elixirCost'), # elixir cost may not be present for all cards\n",
    "                        'evo_status':  card.get('maxEvolutionLevel', 0) # evolutions have no level thus maxEvolutionLevel = 1 denotes evolution present\n",
    "        }\n",
    "        card_info.append(card_details)\n",
    "        \n",
    "    cards = pd.DataFrame(card_info)\n",
    "\n",
    "    # table cleaning\n",
    "    cards['evo_status'] = cards['evo_status'].astype(bool)\n",
    "    cards['card_id'] = cards['card_id'].astype(str)\n",
    "    cards['elixir_cost'] = cards['elixir_cost'].astype('Int64')\n",
    "    cards['elixir_cost'] = cards['elixir_cost'].mask(cards['elixir_cost'].isnull(), None)\n",
    "    \n",
    "    return cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2b7cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to pull matches data into df\n",
    "def get_matches_info(player_ids): \n",
    "    matches_info = []\n",
    "    failed_match_players = []\n",
    "    raw_json_store = {}\n",
    "\n",
    "    for player in player_ids:\n",
    "        try:\n",
    "            response = requests.get(f'{base_url}/players/{player}/battlelog', headers=headers)\n",
    "            if response.status_code != 200:\n",
    "                print(f'failed request for {player.replace(\"%23\", \"#\")}: {response.status_code}')\n",
    "                failed_match_players.append(player.replace('%23', '#'))\n",
    "                continue\n",
    "\n",
    "            json_data = response.json()\n",
    "            raw_json_store[player] = json_data # want to also store json_data for later match_cards pull\n",
    "\n",
    "            for match in json_data:\n",
    "                team = match.get('team')[0]\n",
    "                opp = match.get('opponent')[0]\n",
    "\n",
    "                matches_details = {\n",
    "                    'battle_time': match.get('battleTime'),\n",
    "                    'game_mode': match.get('type'),\n",
    "                    'league': match.get('leagueNumber'),\n",
    "                    'player_id': team.get('tag'),\n",
    "                    'opponent_id': opp.get('tag'),\n",
    "                    'current_global_rank': team.get('globalRank'),\n",
    "                    'starting_rating': team.get('startingTrophies'),\n",
    "                    'rating_change': team.get('trophyChange'),\n",
    "                    'crowns': team.get('crowns'),\n",
    "                    'opp_crowns': opp.get('crowns'),\n",
    "                    'king_tower_hp': team.get('kingTowerHitPoints'),\n",
    "                    'princess_towers_hp': team.get('princessTowersHitPoints'),\n",
    "                    'elixir_leaked': team.get('elixirLeaked')\n",
    "                }\n",
    "\n",
    "                matches_info.append(matches_details)\n",
    "\n",
    "            time.sleep(0.1)  # stay under API rate limit\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'exception for {player.replace(\"%23\", \"#\")}: {e}')\n",
    "            failed_match_players.append(player.replace('%23', '#'))\n",
    "\n",
    "    matches = pd.DataFrame(matches_info) # important note: each row is not necessarily a distinct match because two top players can play in the same match\n",
    "                                         # each row is instead a distinct match-player combo; thus it is possible for the same match to be represented twice, once for each perspective\n",
    "    if matches.empty:\n",
    "        return matches, failed_match_players, raw_json_store\n",
    "\n",
    "    # table cleaning\n",
    "    matches['is_win'] = matches['crowns'] > matches['opp_crowns']\n",
    "    matches['battle_time'] = pd.to_datetime(matches['battle_time'], format='%Y%m%dT%H%M%S.%fZ',\n",
    "                                            utc=True, errors='coerce')\n",
    "    matches['season_id'] = matches['battle_time'].apply(battle_time_to_sid)\n",
    "    matches['match_key'] = (matches['battle_time'].astype(str) + '_' + matches['player_id'].astype(str)) # this col will be the checked col during ingestion\n",
    "    matches = matches[matches['game_mode'] == 'pathOfLegend'].copy()\n",
    "    matches['princess_tower1_hp'] = matches['princess_towers_hp'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else 0)\n",
    "    matches['princess_tower2_hp'] = matches['princess_towers_hp'].apply(lambda x: x[1] if isinstance(x, list) and len(x) > 1 else 0)\n",
    "\n",
    "    matches = matches[[\n",
    "        'match_key','battle_time', 'is_win', 'league', 'player_id', 'opponent_id', 'season_id',\n",
    "        'current_global_rank', 'starting_rating', 'rating_change', 'crowns','opp_crowns',\n",
    "        'king_tower_hp', 'princess_tower1_hp', 'princess_tower2_hp', 'elixir_leaked',\n",
    "    ]]\n",
    "\n",
    "    return matches, failed_match_players, raw_json_store \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1781608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to pull match cards (deck) data from stored json of battlelogs and into df\n",
    "def get_match_card_info(raw_json):\n",
    "    match_card_info = []\n",
    "    for player in raw_json:\n",
    "        for match in raw_json[player]:\n",
    "            for card in match['team'][0]['cards']:\n",
    "                match_card_details = {'game_mode': match['type'],\n",
    "                                      'battle_time': match['battleTime'],\n",
    "                                      'player_id': match['team'][0]['tag'],\n",
    "                                      'card_id': card['id']\n",
    "                }\n",
    "                match_card_info.append(match_card_details)\n",
    "    match_cards = pd.DataFrame(match_card_info)\n",
    "\n",
    "    if match_cards.empty:\n",
    "        return match_cards\n",
    "    \n",
    "    # table cleaning\n",
    "    match_cards['battle_time'] = pd.to_datetime(match_cards['battle_time'], format='%Y%m%dT%H%M%S.%fZ', utc=True)\n",
    "    match_cards['match_key'] = (match_cards['battle_time'].astype(str) + '_' + match_cards['player_id'].astype(str))\n",
    "    match_cards['card_id'] = match_cards['card_id'].astype(str)\n",
    "    match_cards = match_cards[match_cards['game_mode'] == 'pathOfLegend'].copy()\n",
    "    match_cards.drop(columns=['game_mode', 'battle_time'], inplace=True)\n",
    "\n",
    "    return match_cards # like matches, two perspectives of a match are possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e560b95",
   "metadata": {},
   "source": [
    "## III. Load data into database tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3513ada7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new seasons to add.\n"
     ]
    }
   ],
   "source": [
    "# script to populate seasons table db table - must populate before all other tables\n",
    "past_df = last_n_completed_seasons(n=3)\n",
    "current_df = current_plus_n_seasons(n=0)\n",
    "past_and_current_df = pd.concat([past_df, current_df], ignore_index=True).drop_duplicates(subset='season_id') # get current season and last 3 completed seasons\n",
    "\n",
    "past_and_current_ids = past_and_current_df['season_id'].tolist()\n",
    "existing_seasons = set(get_existing_data(engine, 'season_id', 'seasons')) # checking db for already stored seasons; convert to set for fast membership checking\n",
    "all_new_seasons = [s for s in past_and_current_ids if s not in existing_seasons] # initial run will insert last 3 complete sns + current,\n",
    "                                                                                 # subsequent runs insert newest, current sn, if not yet added \n",
    "\n",
    "if all_new_seasons:\n",
    "    season_add_df = past_and_current_df[past_and_current_df['season_id'].isin(all_new_seasons)]\n",
    "    print('New seasons to fetch:', all_new_seasons)\n",
    "    insert_new_rows(engine, season_add_df, 'seasons', 'multi') # populate seasons with new seasons data\n",
    "    print(f'Inserted {len(season_add_df)} new seasons.')\n",
    "else:\n",
    "    print('No new seasons to add.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c3c44b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 0 player(s) into dropped list.\n",
      "Upsert executed on 175 clan rows.\n"
     ]
    }
   ],
   "source": [
    "# script to populate clans db table - must populate before players to respect db foreign key constraint (fk)\n",
    "all_existing_past_seasons_ids = get_existing_data(engine, 'season_id', 'seasons')[:-1] # splice to remove current season\n",
    "season_ranking_df = get_season_rankings(all_existing_past_seasons_ids)\n",
    "tracked_players = season_ranking_df['player_id'].unique().tolist() # this will pick up players who can't ping api due to acc deletion or ban\n",
    "tracked_players = [p.replace('#', '%23') for p in tracked_players]\n",
    "\n",
    "player_df, failed_players = get_player_info(tracked_players)\n",
    "\n",
    "with open('../dropped_data/dropped_players.json', 'r') as f:\n",
    "    existing_dropped = json.load(f)\n",
    "\n",
    "updated_dropped = list(set(existing_dropped + failed_players))\n",
    "\n",
    "with open('../dropped_data/dropped_players.json', 'w') as f:\n",
    "    json.dump(updated_dropped, f) # write failed players (banned or deleted players) into a dropped list to filter by in future runs\n",
    "print(f'Added {len(failed_players)} player(s) into dropped list.')\n",
    "\n",
    "current_membership = player_df['clan_id'].dropna().unique().tolist() # track clans top players are currently in\n",
    "existing_clans = get_existing_data(engine, 'clan_id', 'clans') # track historical clans (where top players have been in) too\n",
    "all_tracked_clans = list(set(current_membership + existing_clans))\n",
    "all_tracked_clans = [c.replace('#', '%23') for c in all_tracked_clans]\n",
    "\n",
    "clan_df, failed_clans = get_clan_info(all_tracked_clans)\n",
    "\n",
    "if not clan_df.empty:\n",
    "    upsert_clan_info(engine, clan_df)\n",
    "    print(f'Upsert executed on {len(clan_df)} clan rows.')\n",
    "else:\n",
    "    print(\"No clans to upsert.\")\n",
    "\n",
    "if failed_clans:\n",
    "    print(f\"{len(failed_clans)} clan(s) failed to fetch. Retry later:\")\n",
    "    print(failed_clans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a013b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert executed on 234 player rows.\n"
     ]
    }
   ],
   "source": [
    "# script to populate players db table - must populate before season_rankings to respect fk\n",
    "upsert_player_info(engine, player_df)\n",
    "print(f'Upsert executed on {len(player_df)} player rows.')\n",
    "\n",
    "if failed_players:\n",
    "    print(f\"{len(failed_players)} player(s) failed to fetch. Already flagged for dropping:\")\n",
    "    print(failed_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6bd4efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new seasons rankings to add.\n"
     ]
    }
   ],
   "source": [
    "# script to populate season_rankings db tables\n",
    "past_df = last_n_completed_seasons(n=3)\n",
    "existing_season_rankings = set(get_existing_data(engine, 'season_id', 'season_rankings'))\n",
    "\n",
    "past_ids = past_df['season_id'].tolist()\n",
    "completed_new_seasons = [s for s in past_ids if s not in existing_season_rankings]\n",
    "\n",
    "if completed_new_seasons:\n",
    "    season_ranking_df = get_season_rankings(completed_new_seasons)\n",
    "    insert_new_rows(engine, season_ranking_df, 'season_rankings', 'multi')\n",
    "    print(f'Inserted {len(season_ranking_df)} new season rankings.')\n",
    "else:\n",
    "    print('No new seasons rankings to add.')\n",
    "\n",
    "if failed_players:\n",
    "    purge_failed_players(engine, failed_players) # need to delete any historical or recently added \n",
    "                                                 # data associated with dropped from all tables of db\n",
    "    print(f'Removed all database records for {len(failed_players)} players:')\n",
    "    print(failed_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb698cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert executed on 120 card rows.\n"
     ]
    }
   ],
   "source": [
    "# script to populate cards db table\n",
    "cards_df = get_card_info() \n",
    "upsert_card_info(engine, cards_df)\n",
    "print(f'Upsert executed on {len(cards_df)} card rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ffd052c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 135 new match views, of which 131 are unique matches.\n",
      "Inserted 1080 new rows into match_cards, spanning 135 match views.\n"
     ]
    }
   ],
   "source": [
    "# script to populate matches and match_cards db tables\n",
    "existing_rank_players = get_existing_data(engine, 'player_id', 'season_rankings')\n",
    "existing_rank_players = {p.replace('#', '%23') for p in existing_rank_players}\n",
    "match_logs, failed_players, raw_json_store = get_matches_info(existing_rank_players)\n",
    "\n",
    "if match_logs.empty:\n",
    "    print('No match data returned.')\n",
    "else:\n",
    "    existing_matches = set(get_existing_data(engine, 'match_key', 'matches'))\n",
    "    match_keys = match_logs['match_key'].tolist()\n",
    "    new_matches = [m for m in match_keys if m not in existing_matches]\n",
    "\n",
    "    if new_matches:\n",
    "        new_matches_df = match_logs[match_logs['match_key'].isin(new_matches)]\n",
    "        unique_matches = new_matches_df.drop_duplicates(subset=['player_id', 'opponent_id'])\n",
    "        cnt_unique_battles = len(unique_matches)\n",
    "\n",
    "        insert_new_rows(engine, new_matches_df, 'matches', None) # must insert before match_cards to respect fk\n",
    "        print(f'Inserted {len(new_matches_df)} new match views, of which {cnt_unique_battles} are unique matches.')\n",
    "        \n",
    "        # mapping the match_view_id identity int generated values in matches db table to match_cards_df rows\n",
    "        match_key_mapping = get_match_key_mapping(engine)\n",
    "        match_cards_df = get_match_card_info(raw_json_store)\n",
    "        new_match_cards_df = match_cards_df[match_cards_df['match_key'].isin(new_matches)]\n",
    "        new_match_cards_df = pd.merge(new_match_cards_df, match_key_mapping, on='match_key', how='inner')\n",
    "        new_match_cards_df = new_match_cards_df[['match_view_id', 'player_id', 'card_id']]\n",
    "\n",
    "        insert_new_rows(engine, new_match_cards_df, 'match_cards', None)\n",
    "        print(f'Inserted {len(new_match_cards_df)} new rows into match_cards, spanning {int(len(new_match_cards_df)/ 8)} match views.')\n",
    "    else:\n",
    "        print('No new match data.')\n",
    "\n",
    "if failed_players:\n",
    "    print(f'{len(failed_players)} player(s) failed during match fetch.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
